---
layout: default
parent: MQTT API
title: Write
nav_order: 30
permalink: /docs/api-mqtt/write
has_children: false
---

# MQTT Write API
{:.no_toc}

The examples below shows how to efficiently write data with mqtt client (`mosquitto_pub`).
The destination topic should be `db/append/`+table_name.

1. TOC
{:toc}

## Multiple records in a publish

```sh
mosquitto_pub -h 127.0.0.1 -p 5653 \
    -t db/append/EXAMPLE \
    -f ./mqtt-data.json
```

- mqtt-data.json

```json
[
    [ "my-car", 1670380342000000000, 32.1 ],
    [ "my-car", 1670380343000000000, 65.4 ],
    [ "my-car", 1670380344000000000, 76.5 ]
]
```

Payload form of above example is array of tuple (array of array in JSON), 
it appends the table with multiple records received through a mqtt message.
It is also possible to publish single tuple like below. 
Machbase Neo accepts both types of payload via mqtt.

## Single record per a publish

```sh
mosquitto_pub -h 127.0.0.1 -p 5653 \
    -t db/append/EXAMPLE \
    -m '[ "my-car", 1670380342000000000, 32.1 ]'
```

Since MQTT is connection oriented protocol, a client program can continuously send data while it keeps the same mqtt session.
It is the real benefit for using MQTT instead of HTTP for writing data.

{: .important }
> In this example, we use `mosquitto_pub` just for demonstration.
> Since it makes a connection to MQTT server and close when it finishes to publish a single message.
> You will barely see performance gains of `append` feature against HTTP `write` api.
>
> Use this MQTT method only when a client can keep a connection relatively long time and send multiple messages.

## Max message size

The maximum size of payload in a PUBILSH message is 256MB by MQTT specification. If a malcious or malfunctioning client sends large messages continuously it can consume all of network bandwidth and computing resource of server side then it may lead server to out of service status. It is good practice to set max message limit as just little more than what client applicatoins demand. The default mqtt max message size is 1MB (`1048576`), it can be adjusted by command line flag like below or `MaxMessageSizeLimit` in the configuration file.

```sh
machbase-neo serve --mqtt-max-message 1048576
```

## Payload formats and compression

Compose the MQTT topic with table name, payload format and compression separated by colon(`:`) to use the payload other than plain JSON.

### Write Compressed JSON

Topic = Table + ':' + "json:gzip"

```sh
mosquitto_pub -h 127.0.0.1 -p 5653 \
    -t db/append/EXAMPLE:json:gzip \
    -f mqtt-data.json.gz
```

### Write CSV

Topic = Table + ':' + "csv"

> Since there is no way to tell machbase-neo whether the first line is header or data.
> The payload should not contain header.

```sh
mosquitto_pub -h 127.0.0.1 -p 5653 \
    -t db/append/EXAMPLE:csv \
    -f mqtt-data.csv
```

### Write Compressed CSV

Topic = Table + ":csv:gzip"

```sh
mosquitto_pub -h 127.0.0.1 -p 5653 \
    -t db/append/EXAMPLE:csv:gzip \
    -f mqtt-data.csv.gz
```

## Topic `db/write/{table}` for `INSERT`

It is strongly recommended using `db/append/{table}` for the better performance through MQTT.
Refer this example of `db/write/{table}` only for the inevitable situation.

```sh
mosquitto_pub -h 127.0.0.1 -p 5653 \
    -t db/write/EXAMPLE \
    -f data-write.json
```

Since `db/write` works in `INSERT ... INTO...` SQL statement, it is required to provide the columns in json payload. Content of `data-write.json` is below.

```json
{
  "data": {
    "columns": ["name", "time", "value"],
    "rows": [
      [ "wave.pi", 1687481466000000000, 1.2345],
      [ "wave.pi", 1687481467000000000, 3.1415]
    ]
  }
}
```

## Topic `db/tql/{file.tql}` for transforming

When the data transforming is required for writing into the database, prepare the proper *tql* script and publish the data to the topic named `db/tql/`+`{tql file includes extension}`.

The example code below shows how to handle multi-lines text data for writing into a table.

```js
// CTX.Body means the payload that arrived via HTTP-POST or MQTT,
// The ?? operator means that if tql is called without content,
//        the right side test data is applied
// It is a good practice while the code is being developed on the tql editor of web-ui.
INPUT( STRING(CTX.Body ?? ` 12345
                            23456
                            78901
                            89012
                            90123
                          `, delimiter('\n')) )
// Apply user-define script for transforming the data
SCRIPT({
  text := import("text")
  times := import("times")
  ctx := import("context")
  key := ctx.key()
  values := ctx.value()
  str := text.trim_space(values[0]) // trim spaces
  if len(str) == 0 {
    ctx.drop() // ignore empty line
  } else {
    str = text.substr(str, 0, 2)  // takes the first 2 letters of the line
    ctx.yieldKey(
      "text_"+key,                // compose new key (which is NAME column of the table)
      times.now(),                // current time
      text.parse_int(str, 10, 64) // convert to number type 
    )
  }
})

// Run this code in the tql editor of web-ui for testing
OUTPUT( CSV() )
// Use OUTPUT( APPEND(table('example'))) for the real action
// OUTPUT( APPEND(table('example')))
```

When the script test has been done on the web-ui,
replace the last line `OUTPUT( CSV() )` with `OUTPUT( APPEND(table('example')))`.

Save the code as "script-post-lines.tql", then send some test data to the topic `db/tql/script-post-lines.tql`.

- `cat lines.txt`

```
110000
221111
332222
442222
```

```sh
mosquitto_pub -h 127.0.0.1 -p 5653 \
    -t db/tql/script-post-lines.tql \
    -f lines.txt
```

Then find if the data was successfuly tranformed and stored.

```sh
$ machbase-neo shell "select * from example where name like 'text_%'"
 ROWNUM  NAME    TIME(LOCAL)              VALUE     
────────────────────────────────────────────────────
      1  text_3  2023-07-14 08:51:10.926  44.000000 
      2  text_0  2023-07-14 08:51:10.925  11.000000 
      3  text_1  2023-07-14 08:51:10.926  22.000000 
      4  text_2  2023-07-14 08:51:10.926  33.000000 
4 rows fetched.
```

For the note, the same *tql* file also works with HTTP POST.

```sh
curl -H "Content-Type: text/plain" \
    --data-binary @lines.txt \
    http://127.0.0.1:5654/db/tql/script-post-lines.tql
```
